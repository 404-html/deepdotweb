---
Research: An efficient Tor crawler
---
<article class="post-listing post-28378 post type-post status-publish format-standard has-post-thumbnail hentry  tag-crawler tag-efficient tag-research 
    <div class="post-inner">
        <span>Posted by: <a href="https://www.deepdotweb.com/author/tamersameeh/" title="">Tamer Sameeh </a></span>
    <span>February 17, 2019</span>
    
    <span><a href="https://www.deepdotweb.com/2019/02/17/research-an-efficient-tor-crawler/#comments">1 Comment</a></span>
    </p>
    <div class="clear"></div>
    <div class="entry">
    <p>The Tor network is by far the most popular darknet, which not only facilitates anonymous browsing, but also hosts a large number of illicit marketplaces, as well as <a href="https://www.deepdotweb.com/2017/04/25/classification-illegal-activities-tor-network/">multiple forms of illegal activities</a>. The Tor protocol protects hosted websites, which are known as hidden services, against undesirable tracking and surveillance. The number of Tor based hidden services has been steadily rising during the past few years. However, a well established method to collect, crawl, and <a href="https://www.deepdotweb.com/2019/01/30/a-novel-system-for-monitoring-and-analysis-of-dark-web-content-a-patent/">analyze content of various Tor based hidden services</a> is still non-existent. Moreover, it is relatively hard to monitor the dynamics of Tor hidden services, mainly due to the low speed of access of the Tor browser.</p>
    <p><a href="https://ieeexplore.ieee.org/abstract/document/8625103">A recently published research paper</a> introduces an efficient <a href="https://www.deepdotweb.com/2018/10/26/research-a-novel-intelligent-rule-based-deep-web-crawler/">crawling method for Tor hidden services</a>, which can monitor the statuses of hidden services, in order to analyze the content present on these websites. Throughout this article, we will take a look at this novel crawler and the results of using it to crawl the content of Tor hidden services.</p>
    <p><img class="wp-image-28381" src="/imgs/2019/02/tor1-jpg.jpeg" alt="tor1.jpg" srcset="/imgs/2019/02/tor1-jpg.jpeg 755w, /imgs/2019/02/tor1-jpg-300x199.jpeg 300w" sizes="(max-width: 755px) 100vw, 755px" /></p>
    <p><strong>Design of the Tor crawler:</strong></p>
    <p>The crawler was designed using Python 3.6. Scrapy was used to develop the crawler, which is a framework specifically designed to develop online data extraction tools, such as web crawlers. Docker was used to design visualization software for the results obtained via the crawler. Privoxy is a local proxy software that was utilized to connect the Tor network to the crawler.</p>
    <p>The crawler starts by sending HTTP requests to hidden services using a user provided group of hidden service onion addresses, then it iterates through each hidden service over the course of a &#8220;browsing session.&#8221; Responses obtained from hidden services, which include HTML pages, are then directly downloaded into a session specific folder generated by the data pipeline of the crawler at runtime. A locally created MySQL database, which records metadata for top level onion domains, URLs, and the browsing time and date, can be preferentially enabled or disabled.</p>
    <p>A log file is created and stored locally including real-time data on requested web pages, ignored domains, raised exceptions, crawling statistics, and other useful information obtained during the period of a crawling session.</p>
    <p><strong>Results obtained via using the crawler:</strong></p>
    <p>To improve the performance of the crawler, the obtained Tor hidden services were analyzed via a special clustering technique and the crawling targets were reduced. Crawling time was further improved by 76% via means of 5 browsers and 5 Docker containers. Via clustering the same Tor hidden services, developers of the crawler were capable of reducing 39% of the crawling time needed for Tor hidden services.</p>
    <p>During the period between January 1st, 2018 and May 31st, 2018, the crawler successfully collected 25,261 onion addresses and discovered 2,527 unique Tor based hidden services. These hidden services were crawled twice a day, resulting in collection of 456,739 HTML pages. Authors of the paper managed to classify contents of 722 Tor hidden services and to analyze the dynamics of these hidden services via the obtained crawler&#8217;s log data and collected HTML pages.</p>
    <p>There was no evidence that the crawler was blocked or impeded by any of the crawled Tor hidden services. Around 1.5 GB of HTML pages downloaded from the crawled hidden services did not include duplicate content. The collected content was parsed via the graphing program, as well as other analysis tools.</p>
    <p>The graphing program parsed through the data obtained via the web crawler and generated connected graphs that illustrate the links existing between the crawled Tor hidden services. The obtained graphs were then dumped in .gefx and .json formats. When rendered via external applications, the graphs initially looked chaotic, yet they can be made to appear more eligible via application of graph drawing algorithms.</p>
    <p><strong>Analyzing the results of the crawler&#8217;s experiment:</strong></p>
    <p>This newly developed dark web crawler and associated graphing program were designed namely with functionality in mind and were only tested using a single platform (Ubuntu). For wider scale use by individuals and organizations, this crawler must be tested on multiple platforms/operating systems and made simpler to install and use. Future versions of this crawler could be modified to store more information between different crawling sessions so that the crawler would not yield redundant work.</p>
    <p>For instance, the crawler might denote which of the onion addresses in the initial hidden service URL list were not operational and either only regularly attempts sending connection requests or ignores them completely. Moreover, the crawler could be programmed to automatically add to the initial list any newly discovered hidden service to be directly accessed during future crawling sessions.</p>
    <p>Eventually, the content obtained by the crawler, as well as the graphs created by the graphing program, have to be modified in order to perform thorough analysis on content of the Tor network and enable the creation of real-time reports on the content of the Tor Network. This feature will be valuable for both researchers as well as law-enforcement professionals who seek to understand and/or monitor the Tor network.</p>
    </div>
    <span style="display:none"><a href="https://www.deepdotweb.com/tag/crawler/" rel="tag">crawler</a> <a href="https://www.deepdotweb.com/tag/efficient/" rel="tag">efficient</a> <a href="https://www.deepdotweb.com/tag/research/" rel="tag">research</a> <a href="https://www.deepdotweb.com/tag/tor/" rel="tag">tor</a></span> <span style="display:none" class="updated">2019-02-17</span>
    <div style="display:none" class="vcard author" itemprop="author" itemscope itemtype="http://schema.org/Person"><strong class="fn" itemprop="name"><a href="https://www.deepdotweb.com/author/tamersameeh/" title="Posts by Tamer Sameeh" rel="author">Tamer Sameeh</a></strong></div>
    </div>
</article>

